{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb6a816-ff6f-403b-8622-0ca33cea960b",
   "metadata": {},
   "source": [
    "# Tarefa 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01af968-8131-4047-936f-ee55315b09a4",
   "metadata": {},
   "source": [
    "**1.** Monte um passo a passo para o algoritmo RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527cc51a-cdf8-44ae-b8d8-93ebce1009e1",
   "metadata": {},
   "source": [
    "Similar ao Bagging, o Random Forest segue estes passos:\n",
    "\n",
    "Bootstrap + Seleção de Características: Assim como no Bagging, o Random Forest utiliza amostras aleatórias com reposição do conjunto de dados de treinamento original. Contudo, em cada amostra, apenas um subconjunto aleatório de variáveis é selecionado (feature selection). Para problemas de classificação, é comum escolher a raiz quadrada do número total de variáveis, enquanto em problemas de regressão, um terço das variáveis é frequentemente utilizado.\n",
    "\n",
    "Modelagem com Árvores de Decisão: Nesta fase, um modelo de Machine Learning, especificamente uma árvore de decisão, é treinado de maneira independente em cada amostra bootstrap, utilizando as variáveis aleatórias definidas no passo anterior.\n",
    "\n",
    "Agregação: Por último, os resultados de cada modelo independente (cada árvore de decisão) são agregados para obter uma previsão final. Em problemas de classificação, a agregação é geralmente realizada por meio de voto majoritário, escolhendo a classe prevista com maior frequência entre os modelos individuais como a classe final. Em problemas de regressão, a agregação é feita calculando a média das previsões dos modelos individuais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805122b5-5f98-4013-bac2-d36ed341325c",
   "metadata": {},
   "source": [
    "**2.** Explique com suas palavras o Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7b205-08c5-45a8-a29e-45e1c9baf2b5",
   "metadata": {},
   "source": [
    "O Random Forest é uma extensão do Bootstrap Aggregating, conhecido como Bagging, que proporciona melhorias em desempenho e resultados. Semelhante ao Bagging, o Random Forest é um método de combinação de modelos de Machine Learning, onde cada modelo é treinado em variações do conjunto de dados original chamadas amostras bootstrap. Essas amostras consistem em subconjuntos aleatórios do conjunto de dados original, permitindo repetições e mantendo o mesmo número de linhas.\n",
    "\n",
    "A diferença chave do Random Forest está no uso de uma quantidade determinada e aleatória de variáveis em cada modelo, especialmente em modelos de árvore de decisão. Essa abordagem visa reduzir a variância dos resultados e mitigar o risco de overfitting. Na etapa de obtenção da previsão final, a agregação dos modelos é realizada de maneira semelhante ao Bagging, utilizando a média para regressão e a votação para classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a54f311-a631-4d9c-a2e0-92064484db82",
   "metadata": {},
   "source": [
    "**3.** Qual a diferença entre Bagging e Random Forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd86441-282d-434f-8a6c-c84f668a7a31",
   "metadata": {},
   "source": [
    "\n",
    "A diferença entre Bagging e Random Forest reside no desempenho e na redução da variância nos resultados dos modelos. Bagging é uma técnica mais genérica de combinação de modelos de Machine Learning que utiliza amostragem aleatória. Por outro lado, Random Forest é uma variação mais específica desse método que incorpora árvores de decisão.\n",
    "\n",
    "No Random Forest, cada modelo é treinado em subconjuntos aleatórios do conjunto de dados original, com uma quantidade reduzida e aleatória de variáveis consideradas em cada modelo. Essa abordagem aumenta a robustez do modelo, e ao combinar os resultados dos modelos, a previsão final tende a ser mais precisa do que no Bagging. Portanto, o Random Forest é uma extensão aprimorada do Bagging, proporcionando melhor desempenho e uma redução adicional na variância dos resultados.\n",
    "\n",
    "A afirmação \"Random Forest funciona melhor que o Bagging, pois as árvores amostradas são mais independentes (menor correlação)\" destaca que, devido à seleção mais restrita e aleatória de variáveis em cada modelo do Random Forest, as árvores tornam-se mais independentes entre si, resultando em menor correlação e, consequentemente, melhor desempenho."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afea5b5-6bed-4c12-adf1-988ce95e0db1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
